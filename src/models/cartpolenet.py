# -*- coding: utf-8 -*-
"""CartpoleNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UmkZn_OxdUktgludHWZ4yCYBbIYfsJ3E
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class CartPoleNet(nn.Module): 
  def __init__(self):
    super(CartPoleNet, self).__init__()
    self.conv1 = nn.Conv2d(1, 6, 3)
    self.fc1 = nn.Linear(149 * 199 * 6, 120) # resulting width x height from conv and max
    self.fc2 = nn.Linear(120, 100)
    self.fc3 = nn.Linear(100, 50)
    self.fc4 = nn.Linear(50, 4)

  def forward(self, x):
    x = F.max_pool2d(F.relu(self.conv1(x)), 2) 
    x = x.view(-1, self.num_flat_features(x))
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = F.relu(self.fc3(x))
    x = self.fc4(x)
    return x

  def num_flat_features(self, x):
    size = x.size()[1:]  # all dimensions except the batch dimension
    num_features = 1
    for s in size:
        num_features *= s
    return num_features

net = CartPoleNet()
print(net)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

img = cv2.imread('4.jpg', 0)

cv2_imshow(img)
img = torch.from_numpy(img).unsqueeze(0).unsqueeze(0)

input = torch.randn(1, 1, 300, 400)
out = net(input)
print(out)

print(type(input))
print(type(img))

print(input.size())
print(img.size())
img = img.float()
print(input.dtype)
print(img.dtype)

out = net(img)

